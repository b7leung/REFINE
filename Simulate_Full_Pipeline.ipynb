{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T01:23:58.970730Z",
     "start_time": "2022-05-30T01:23:58.946538Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T01:24:02.511626Z",
     "start_time": "2022-05-30T01:23:58.973294Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import trimesh\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch3d.io import save_obj\n",
    "from pytorch3d.structures import Pointclouds\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    FoVOrthographicCameras, \n",
    "    PointsRasterizationSettings,\n",
    "    PointsRenderer,\n",
    "    PointsRasterizer,\n",
    "    AlphaCompositor,\n",
    "    OpenGLPerspectiveCameras, \n",
    "    NormWeightedCompositor,\n",
    "    look_at_view_transform,\n",
    "    TexturesVertex,\n",
    "    Textures,\n",
    "    PointLights\n",
    ")\n",
    "\n",
    "from utils import general_utils\n",
    "from utils import visualization_tools\n",
    "from mesh_refiner import MeshRefiner\n",
    "from utils.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T01:24:02.553057Z",
     "start_time": "2022-05-30T01:24:02.513581Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "cfg = general_utils.load_config(\"config.yaml\")\n",
    "\n",
    "instances = {}\n",
    "instances[\"f390b1b28b6dda03dc57b3e43c28d486\"] = {\"input_img_path\": \"data/examples/f390b1b28b6dda03dc57b3e43c28d486.png\", \"original_mesh_path\":\"data/examples/f390b1b28b6dda03dc57b3e43c28d486.obj\", \"gt_mesh_path\": \"data/ground_truth/f390b1b28b6dda03dc57b3e43c28d486.obj\", \"azim\":150, \"elev\":40, \"dist\":1.2}\n",
    "instances[\"eb8fe6d82d195ab5bc8feea465aa74f2\"] = {\"input_img_path\": \"data/examples/eb8fe6d82d195ab5bc8feea465aa74f2.png\", \"original_mesh_path\":\"data/examples/eb8fe6d82d195ab5bc8feea465aa74f2.obj\", \"gt_mesh_path\": \"data/ground_truth/eb8fe6d82d195ab5bc8feea465aa74f2.obj\", \"azim\":336, \"elev\":40, \"dist\":1.2}\n",
    "instances[\"f6b96f56212f55363023a5c0cae3fffe\"] = {\"input_img_path\": \"data/examples/f6b96f56212f55363023a5c0cae3fffe.png\", \"original_mesh_path\":\"data/examples/f6b96f56212f55363023a5c0cae3fffe.obj\", \"gt_mesh_path\": \"data/ground_truth/f6b96f56212f55363023a5c0cae3fffe.obj\", \"azim\":323, \"elev\":40, \"dist\":1.3}\n",
    "instances[\"0146\"] = {\"input_img_path\": \"data/examples/0146.png\", \"original_mesh_path\":\"data/examples/0146.obj\", \"gt_mesh_path\": \"data/ground_truth/0146.obj\", \"azim\":69, \"elev\":22, \"dist\":1.1}\n",
    "instances[\"OWILD_White_Toy_Rv_090\"] = {\"input_img_path\": \"data/examples/OWILD_White_Toy_Rv_090.png\", \"original_mesh_path\":\"data/examples/OWILD_White_Toy_Rv_090.obj\", \"gt_mesh_path\": \"data/ground_truth/White_Toy_Rv.obj\", \"azim\":175, \"elev\":6, \"dist\":1}\n",
    "instances[\"OOWL_Alta_Dena_Whipped_Cream_Can_090\"] = {\"input_img_path\": \"data/examples/OOWL_Alta_Dena_Whipped_Cream_Can_090.png\", \"original_mesh_path\":\"data/examples/OOWL_Alta_Dena_Whipped_Cream_Can_090.obj\", \"gt_mesh_path\": \"data/ground_truth/Alta_Dena_Whipped_Cream_Can.obj\", \"azim\":189, \"elev\":8, \"dist\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T01:27:05.631427Z",
     "start_time": "2022-05-30T01:24:02.554475Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for instance_name in instances:\n",
    "    \n",
    "    # setting up\n",
    "    input_img_path = instances[instance_name][\"input_img_path\"]\n",
    "    original_mesh_path = instances[instance_name][\"original_mesh_path\"]\n",
    "    azim = instances[instance_name][\"azim\"]\n",
    "    elev = instances[instance_name][\"elev\"]\n",
    "    dist = instances[instance_name][\"dist\"]\n",
    "    input_image = np.asarray(Image.open(input_img_path))\n",
    "    with torch.no_grad():\n",
    "        input_mesh = general_utils.load_untextured_mesh(original_mesh_path, device)\n",
    "    R, T = look_at_view_transform(dist, elev, azim)\n",
    "    \n",
    "    # performing REFINE\n",
    "    mesh_refiner = MeshRefiner(cfg, device)\n",
    "    refined_mesh, refinement_info = mesh_refiner.refine_mesh(input_mesh, input_image, R, T, record_debug=True)\n",
    "    \n",
    "    # plotting loss, visualizing results, and saving refined mesh\n",
    "    refined_mesh_path = os.path.join(\"data/REFINEd_output\", \"{}_refined.obj\".format(instance_name))\n",
    "    save_obj(refined_mesh_path, refined_mesh.verts_packed(), refined_mesh.faces_packed())\n",
    "    refined_mesh = general_utils.load_untextured_mesh(refined_mesh_path, device)\n",
    "    refinement_info[\"loss_info\"].plot.line(x='iteration', y='total_loss', title=\"{}\".format(instance_name))\n",
    "    visualization_tools.show_refinement_results(input_image, input_mesh, refined_mesh, R, T, device, num_novel_view=1)\n",
    "    \n",
    "    # evaluation\n",
    "    gt_mesh_path = instances[instance_name][\"gt_mesh_path\"]\n",
    "    metrics_before = evaluate(original_mesh_path, gt_mesh_path, device)\n",
    "    metrics_after = evaluate(refined_mesh_path, gt_mesh_path, device)\n",
    "    for metric in metrics_before:\n",
    "        print(\"{}: {} -> {}\".format(metric, metrics_before[metric], metrics_after[metric]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
